{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Predict Subject Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089ae5cacf454cf3a3af1bde7671b6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../../allennlp')\n",
    "sys.path.insert(0, '../../')\n",
    "from tqdm import tqdm_notebook\n",
    "from lib.utils import get_connection \n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "tqdm_notebook().pandas()\n",
    "connection = get_connection()\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../lib/simple_qa.py:36: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  filename, header=None, names=['subject', 'relation', 'object', 'question'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17188</th>\n",
       "      <td>02_286</td>\n",
       "      <td>location/place_with_neighborhoods/neighborhoods</td>\n",
       "      <td>075s73</td>\n",
       "      <td>which town is in new york city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>01bg1k</td>\n",
       "      <td>baseball/baseball_player/position_s</td>\n",
       "      <td>017drs</td>\n",
       "      <td>does pee wee reese play shortstop or power for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21187</th>\n",
       "      <td>06tw28</td>\n",
       "      <td>music/artist/track</td>\n",
       "      <td>0vp3fq</td>\n",
       "      <td>What is a track by lutricia mcneal?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18730</th>\n",
       "      <td>0slws_1</td>\n",
       "      <td>music/release_track/recording</td>\n",
       "      <td>0wzyx1</td>\n",
       "      <td>Name a recording by nelson mandela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>01m1y</td>\n",
       "      <td>media_common/netflix_genre/titles</td>\n",
       "      <td>0crryw4</td>\n",
       "      <td>Name a film in the netflix genre celtic music.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject                                         relation   object  \\\n",
       "17188   02_286  location/place_with_neighborhoods/neighborhoods   075s73   \n",
       "4793    01bg1k              baseball/baseball_player/position_s   017drs   \n",
       "21187   06tw28                               music/artist/track   0vp3fq   \n",
       "18730  0slws_1                    music/release_track/recording   0wzyx1   \n",
       "10014    01m1y                media_common/netflix_genre/titles  0crryw4   \n",
       "\n",
       "                                                question  \n",
       "17188                     which town is in new york city  \n",
       "4793   does pee wee reese play shortstop or power for...  \n",
       "21187                What is a track by lutricia mcneal?  \n",
       "18730                 Name a recording by nelson mandela  \n",
       "10014     Name a film in the netflix genre celtic music.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the end-to-end pipeline on the development set\n",
    "\n",
    "from lib.simple_qa import load_simple_qa \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df_dev, = load_simple_qa(test=True)\n",
    "df_dev = shuffle(df_dev, random_state=123)\n",
    "df_dev[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Subject Name Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/arbeitsdaten46/projekte/dialog-1/kanjurva/Simple-QA-EMNLP-2018/env/lib/python3.6/site-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "/mount/arbeitsdaten46/projekte/dialog-1/kanjurva/Simple-QA-EMNLP-2018/env/lib/python3.6/site-packages/allennlp/modules/conditional_random_field.py:37: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  torch.nn.init.xavier_normal(self.transitions)\n",
      "/mount/arbeitsdaten46/projekte/dialog-1/kanjurva/Simple-QA-EMNLP-2018/env/lib/python3.6/site-packages/allennlp/modules/conditional_random_field.py:38: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  torch.nn.init.normal(self.start_transitions)\n",
      "/mount/arbeitsdaten46/projekte/dialog-1/kanjurva/Simple-QA-EMNLP-2018/env/lib/python3.6/site-packages/allennlp/modules/conditional_random_field.py:39: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  torch.nn.init.normal(self.end_transitions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what major cities does u.s. route 2 run through ?\n",
      "Predicted Tags: ['O', 'O', 'O', 'O', 'I', 'I', 'I', 'O', 'O', 'O']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/arbeitsdaten46/projekte/dialog-1/kanjurva/Simple-QA-EMNLP-2018/env/lib/python3.6/site-packages/allennlp/data/fields/text_field.py:119: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  tensor = Variable(torch.LongTensor(padded_array), volatile=not for_training)\n",
      "/mount/arbeitsdaten46/projekte/dialog-1/kanjurva/Simple-QA-EMNLP-2018/env/lib/python3.6/site-packages/allennlp/modules/encoder_base.py:93: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  num_valid = torch.sum(mask[:, 0]).int().data[0]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import lib.import_notebook\n",
    "from allennlp.models.archival import load_archive\n",
    "from allennlp.service.predictors import Predictor\n",
    "        \n",
    "ARCHIVE = load_archive('../../pretrained_models/subject_recognition_grid_search_2.02_11_20:56:18/model.tar.gz', cuda_device=0)\n",
    "PREDICTOR = Predictor.from_archive(ARCHIVE, 'sentence-tagger')\n",
    "\n",
    "## TEST ##\n",
    "question = 'what major cities does u.s. route 2 run through ?'\n",
    "print('Question:', question)\n",
    "print('Predicted Tags:', PREDICTOR.predict_json({'sentence': question}, 0)['tags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top K Model Decoder\n",
    "\n",
    "The best subject name span is not always found in our KG; therefore, here we define a top k viterbi decoder. This allows us to get the top k subject names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# FROM: https://gist.github.com/Deepblue129/afaa3613a99a8e7213d2efdd02ae4762 \n",
    "def viterbi_decode(tag_sequence: torch.Tensor, transition_matrix: torch.Tensor, top_k: int=5):\n",
    "    \"\"\"\n",
    "    Perform Viterbi decoding in log space over a sequence given a transition matrix\n",
    "    specifying pairwise (transition) potentials between tags and a matrix of shape\n",
    "    (sequence_length, num_tags) specifying unary potentials for possible tags per\n",
    "    timestep.\n",
    "    Parameters\n",
    "    ----------\n",
    "    tag_sequence : torch.Tensor, required.\n",
    "        A tensor of shape (sequence_length, num_tags) representing scores for\n",
    "        a set of tags over a given sequence.\n",
    "    transition_matrix : torch.Tensor, required.\n",
    "        A tensor of shape (num_tags, num_tags) representing the binary potentials\n",
    "        for transitioning between a given pair of tags.\n",
    "    top_k : int, required.\n",
    "        Integer defining the top number of paths to decode.\n",
    "    Returns\n",
    "    -------\n",
    "    viterbi_path : List[int]\n",
    "        The tag indices of the maximum likelihood tag sequence.\n",
    "    viterbi_score : float\n",
    "        The score of the viterbi path.\n",
    "    \"\"\"\n",
    "    sequence_length, num_tags = list(tag_sequence.size())\n",
    "\n",
    "    path_scores = []\n",
    "    path_indices = []\n",
    "    # At the beginning, the maximum number of permutations is 1; therefore, we unsqueeze(0)\n",
    "    # to allow for 1 permutation.\n",
    "    path_scores.append(tag_sequence[0, :].unsqueeze(0))\n",
    "    # assert path_scores[0].size() == (n_permutations, num_tags)\n",
    "\n",
    "    # Evaluate the scores for all possible paths.\n",
    "    for timestep in range(1, sequence_length):\n",
    "        # Add pairwise potentials to current scores.\n",
    "        # assert path_scores[timestep - 1].size() == (n_permutations, num_tags)\n",
    "        summed_potentials = path_scores[timestep - 1].unsqueeze(2) + transition_matrix\n",
    "        summed_potentials = summed_potentials.view(-1, num_tags)\n",
    "\n",
    "        # Best pairwise potential path score from the previous timestep. \n",
    "        max_k = min(summed_potentials.size()[0], top_k)\n",
    "        scores, paths = torch.topk(summed_potentials, k=max_k, dim=0)\n",
    "        # assert scores.size() == (n_permutations, num_tags)\n",
    "        # assert paths.size() == (n_permutations, num_tags)\n",
    "\n",
    "        scores = tag_sequence[timestep, :] + scores\n",
    "        # assert scores.size() == (n_permutations, num_tags)\n",
    "        path_scores.append(scores)\n",
    "        path_indices.append(paths.squeeze())\n",
    "\n",
    "    # Construct the most likely sequence backwards.\n",
    "    path_scores = path_scores[-1].view(-1)\n",
    "    max_k = min(path_scores.size()[0], top_k)\n",
    "    viterbi_scores, best_paths = torch.topk(path_scores, k=max_k, dim=0)\n",
    "    viterbi_paths = []\n",
    "    for i in range(max_k):\n",
    "        viterbi_path = [best_paths[i]]\n",
    "        for backward_timestep in reversed(path_indices):\n",
    "            viterbi_path.append(int(backward_timestep.view(-1)[viterbi_path[-1]]))\n",
    "        # Reverse the backward path.\n",
    "        viterbi_path.reverse()\n",
    "        # Viterbi paths uses (num_tags * n_permutations) nodes; therefore, we need to modulo.\n",
    "        viterbi_path = [j % num_tags for j in viterbi_path]\n",
    "        viterbi_paths.append(viterbi_path)\n",
    "    return viterbi_paths, viterbi_scores\n",
    "\n",
    "## TEST ##\n",
    "sequence_logits = torch.FloatTensor([[1, 0, 0, 4], [1, 0, 6, 2], [0, 3, 0, 4]])\n",
    "transition_matrix = torch.zeros([4, 4])\n",
    "transition_matrix[0, 0] = 1\n",
    "transition_matrix[2, 1] = 5\n",
    "indices, value = viterbi_decode(sequence_logits, transition_matrix)\n",
    "assert indices[0] == [3, 2, 1]\n",
    "assert value[0] == 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Score: 101.382729] Path: ['O', 'O', 'O', 'O', 'I', 'I', 'I', 'O', 'O', 'O']\n",
      "[Score: 83.410515] Path: ['O', 'O', 'O', 'O', 'I', 'I', 'I', 'O', 'I', 'O']\n",
      "[Score: 82.760170] Path: ['O', 'O', 'O', 'O', 'I', 'I', 'O', 'O', 'O', 'O']\n",
      "[Score: 82.228661] Path: ['O', 'O', 'O', 'O', 'I', 'O', 'I', 'O', 'O', 'O']\n",
      "[Score: 81.733078] Path: ['O', 'O', 'O', 'O', 'I', 'I', 'I', 'O', 'O', 'I']\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Originally From:\n",
    "# https://github.com/allenai/allennlp/blob/master/allennlp/modules/conditional_random_field.py#L162\n",
    "def viterbi_tags(logits: List[List[int]], mask: List[int], top_k: int) -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    Uses viterbi algorithm to find most likely tags for the given inputs.\n",
    "    \"\"\"\n",
    "    logits = torch.FloatTensor(logits)\n",
    "    mask = torch.LongTensor(mask)\n",
    "    \n",
    "    max_seq_length, num_tags = logits.size()\n",
    "\n",
    "    # Augment transitions matrix with start and end transitions\n",
    "    start_tag = num_tags\n",
    "    end_tag = num_tags + 1\n",
    "    transitions = torch.Tensor(num_tags + 2, num_tags + 2).fill_(-10000.)\n",
    "\n",
    "    transitions[:num_tags, :num_tags] = ARCHIVE.model.crf.transitions.data\n",
    "    transitions[start_tag, :num_tags] = ARCHIVE.model.crf.start_transitions.data\n",
    "    transitions[:num_tags, end_tag] = ARCHIVE.model.crf.end_transitions.data\n",
    "\n",
    "    # Pad the max sequence length by 2 to account for start_tag + end_tag.\n",
    "    tag_sequence = torch.Tensor(max_seq_length + 2, num_tags + 2)\n",
    "\n",
    "    sequence_length = torch.sum(mask)\n",
    "\n",
    "    # Start with everything totally unlikely\n",
    "    tag_sequence.fill_(-10000.)\n",
    "    # At timestep 0 we must have the START_TAG\n",
    "    tag_sequence[0, start_tag] = 0.\n",
    "    # At steps 1, ..., sequence_length we just use the incoming logits\n",
    "    logits[:sequence_length]\n",
    "    tag_sequence[1:(sequence_length + 1), :num_tags] = logits[:sequence_length]\n",
    "    # And at the last timestep we must have the END_TAG\n",
    "    tag_sequence[sequence_length + 1, end_tag] = 0.\n",
    "\n",
    "    # We pass the tags and the transitions to ``viterbi_decode``.\n",
    "    viterbi_paths, viterbi_scores = viterbi_decode(tag_sequence[:(sequence_length + 2)], transitions, top_k)\n",
    "    # Get rid of START and END sentinels and append.\n",
    "    viterbi_paths = [path[1:-1] for path in viterbi_paths]\n",
    "    # Ensure that hidden tokens START and END are not in path\n",
    "    viterbi_paths = [path for path in viterbi_paths if 2 not in path and 3 not in path]\n",
    "    # Translate indexes to labels\n",
    "    viterbi_paths = [\n",
    "        [ARCHIVE.model.vocab.get_token_from_index(i, namespace=\"labels\")\n",
    "         for i in paths] for paths in viterbi_paths\n",
    "    ]\n",
    "    return viterbi_paths, viterbi_scores\n",
    "\n",
    "## TEST ##\n",
    "top_k = 5\n",
    "predicted = PREDICTOR.predict_json({'sentence': 'what major cities does u.s. route 2 run through ?'}, 0)\n",
    "viterbi_paths, viterbi_scores = viterbi_tags(predicted['logits'], predicted['mask'], top_k)\n",
    "\n",
    "# Best viterbi_paths should equal to predicted tags\n",
    "assert predicted['tags'] == viterbi_paths[0]\n",
    "\n",
    "for i in range(top_k):\n",
    "    print('[Score: %f] Path:' % viterbi_scores[i], viterbi_paths[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap Up\n",
    "\n",
    "Put the model and top k decoder together. Predict the subject name accross all the examples in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Output:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'u.s. route 2',\n",
       "  'score': tensor(101.3827),\n",
       "  'start_index': 4,\n",
       "  'end_index': 7},\n",
       " {'name': 'u.s. route',\n",
       "  'score': tensor(82.7602),\n",
       "  'start_index': 4,\n",
       "  'end_index': 6},\n",
       " {'name': 'does u.s. route 2',\n",
       "  'score': tensor(80.7309),\n",
       "  'start_index': 3,\n",
       "  'end_index': 7},\n",
       " {'name': 'route 2',\n",
       "  'score': tensor(80.7288),\n",
       "  'start_index': 5,\n",
       "  'end_index': 7},\n",
       " {'name': 'u.s. route 2 run',\n",
       "  'score': tensor(79.8302),\n",
       "  'start_index': 4,\n",
       "  'end_index': 8},\n",
       " {'name': 'u.s.', 'score': tensor(65.8604), 'start_index': 4, 'end_index': 5},\n",
       " {'name': 'u.s. route 2 run through',\n",
       "  'score': tensor(64.1123),\n",
       "  'start_index': 4,\n",
       "  'end_index': 9},\n",
       " {'name': '2', 'score': tensor(63.8291), 'start_index': 6, 'end_index': 7},\n",
       " {'name': 'does u.s. route',\n",
       "  'score': tensor(62.1083),\n",
       "  'start_index': 3,\n",
       "  'end_index': 6},\n",
       " {'name': 'route', 'score': tensor(62.1063), 'start_index': 5, 'end_index': 6},\n",
       " {'name': 'cities does u.s. route 2',\n",
       "  'score': tensor(60.5656),\n",
       "  'start_index': 2,\n",
       "  'end_index': 7},\n",
       " {'name': 'does u.s. route 2 run',\n",
       "  'score': tensor(59.1783),\n",
       "  'start_index': 3,\n",
       "  'end_index': 8},\n",
       " {'name': 'route 2 run',\n",
       "  'score': tensor(59.1763),\n",
       "  'start_index': 5,\n",
       "  'end_index': 8},\n",
       " {'name': 'u.s. route 2 run through ?',\n",
       "  'score': tensor(46.7169),\n",
       "  'start_index': 4,\n",
       "  'end_index': 10},\n",
       " {'name': 'does u.s.',\n",
       "  'score': tensor(45.2086),\n",
       "  'start_index': 3,\n",
       "  'end_index': 5},\n",
       " {'name': 'does u.s. route 2 run through',\n",
       "  'score': tensor(43.4604),\n",
       "  'start_index': 3,\n",
       "  'end_index': 9},\n",
       " {'name': 'route 2 run through',\n",
       "  'score': tensor(43.4584),\n",
       "  'start_index': 5,\n",
       "  'end_index': 9},\n",
       " {'name': '2 run', 'score': tensor(42.2765), 'start_index': 6, 'end_index': 8},\n",
       " {'name': 'cities does u.s. route',\n",
       "  'score': tensor(41.9431),\n",
       "  'start_index': 2,\n",
       "  'end_index': 6},\n",
       " {'name': 'cities does u.s. route 2 run',\n",
       "  'score': tensor(39.0131),\n",
       "  'start_index': 2,\n",
       "  'end_index': 8},\n",
       " {'name': 'major cities does u.s. route 2',\n",
       "  'score': tensor(38.2148),\n",
       "  'start_index': 1,\n",
       "  'end_index': 7},\n",
       " {'name': 'through',\n",
       "  'score': tensor(29.4886),\n",
       "  'start_index': 8,\n",
       "  'end_index': 9},\n",
       " {'name': '?', 'score': tensor(27.8112), 'start_index': 9, 'end_index': 10},\n",
       " {'name': '2 run through',\n",
       "  'score': tensor(26.5586),\n",
       "  'start_index': 6,\n",
       "  'end_index': 9},\n",
       " {'name': 'does u.s. route 2 run through ?',\n",
       "  'score': tensor(26.0651),\n",
       "  'start_index': 3,\n",
       "  'end_index': 10},\n",
       " {'name': 'route 2 run through ?',\n",
       "  'score': tensor(26.0630),\n",
       "  'start_index': 5,\n",
       "  'end_index': 10},\n",
       " {'name': 'cities does u.s.',\n",
       "  'score': tensor(25.0433),\n",
       "  'start_index': 2,\n",
       "  'end_index': 5},\n",
       " {'name': 'cities',\n",
       "  'score': tensor(25.0412),\n",
       "  'start_index': 2,\n",
       "  'end_index': 3},\n",
       " {'name': 'does', 'score': tensor(24.5547), 'start_index': 3, 'end_index': 4},\n",
       " {'name': 'run', 'score': tensor(23.6539), 'start_index': 7, 'end_index': 8},\n",
       " {'name': 'cities does u.s. route 2 run through',\n",
       "  'score': tensor(23.2952),\n",
       "  'start_index': 2,\n",
       "  'end_index': 9},\n",
       " {'name': 'what', 'score': tensor(23.0029), 'start_index': 0, 'end_index': 1},\n",
       " {'name': 'major', 'score': tensor(22.8557), 'start_index': 1, 'end_index': 2},\n",
       " {'name': 'major cities does u.s. route',\n",
       "  'score': tensor(19.5922),\n",
       "  'start_index': 1,\n",
       "  'end_index': 6},\n",
       " {'name': 'major cities does u.s. route 2 run',\n",
       "  'score': tensor(16.6622),\n",
       "  'start_index': 1,\n",
       "  'end_index': 8},\n",
       " {'name': 'what major cities does u.s. route 2',\n",
       "  'score': tensor(16.0111),\n",
       "  'start_index': 0,\n",
       "  'end_index': 7},\n",
       " {'name': 'through ?',\n",
       "  'score': tensor(12.0933),\n",
       "  'start_index': 8,\n",
       "  'end_index': 10},\n",
       " {'name': '2 run through ?',\n",
       "  'score': tensor(9.1633),\n",
       "  'start_index': 6,\n",
       "  'end_index': 10},\n",
       " {'name': 'run through',\n",
       "  'score': tensor(7.9360),\n",
       "  'start_index': 7,\n",
       "  'end_index': 9},\n",
       " {'name': 'cities does u.s. route 2 run through ?',\n",
       "  'score': tensor(5.8998),\n",
       "  'start_index': 2,\n",
       "  'end_index': 10},\n",
       " {'name': 'cities does',\n",
       "  'score': tensor(4.3894),\n",
       "  'start_index': 2,\n",
       "  'end_index': 4},\n",
       " {'name': 'major cities does u.s.',\n",
       "  'score': tensor(2.6925),\n",
       "  'start_index': 1,\n",
       "  'end_index': 5},\n",
       " {'name': 'major cities',\n",
       "  'score': tensor(2.6904),\n",
       "  'start_index': 1,\n",
       "  'end_index': 3},\n",
       " {'name': 'major cities does u.s. route 2 run through',\n",
       "  'score': tensor(0.9443),\n",
       "  'start_index': 1,\n",
       "  'end_index': 9},\n",
       " {'name': 'what major',\n",
       "  'score': tensor(0.6520),\n",
       "  'start_index': 0,\n",
       "  'end_index': 2}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "\n",
    "def predict_subject_name(tokens, top_k=500):\n",
    "    # Predict Tags\n",
    "    predicted = PREDICTOR.predict_json({'sentence': ' '.join(tokens)}, 0)\n",
    "    viterbi_paths, viterbi_scores = viterbi_tags(predicted['logits'], predicted['mask'], top_k)\n",
    "    \n",
    "    predicted_subject_names = []\n",
    "    for tags, score in zip(viterbi_paths, viterbi_scores):\n",
    "        assert len(tags) == len(tokens)\n",
    "        # Ignore if multiple subject names are selected\n",
    "        n_subjects = sum(tags[i] == 'I' and (i - 1 == -1 or tags[i - 1] == 'O') for i in range(len(tags)))\n",
    "        if n_subjects == 1:\n",
    "            predicted_subject_name = ' '.join([tokens[i] for i, tag in\n",
    "                                               enumerate(tags) if tag == 'I'])\n",
    "            start_index = [i for i, tag in enumerate(tags) \n",
    "                           if tag == 'I' and (i == 0 or tags[i - 1] == 'O')][0]\n",
    "            end_index = [i for i, tag in enumerate(tags) \n",
    "                         if tag == 'I' and (i == len(tags) - 1 or tags[i + 1] == 'O')][0] + 1\n",
    "            predicted_subject_names.append({\n",
    "                'name': predicted_subject_name,\n",
    "                'score': score,\n",
    "                'start_index': start_index,\n",
    "                'end_index': end_index,\n",
    "            })\n",
    "    return predicted_subject_names\n",
    "\n",
    "## TEST ##\n",
    "print('Sample Output:')\n",
    "predict_subject_name(['what', 'major', 'cities', 'does', 'u.s.', 'route', '2', 'run', 'through', '?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../../notebooks/Simple QA Models/Subject Recognition Data.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf907ed18bc477395ea1de5de390e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../../notebooks/Simple QA Numbers/HYPOTHESIS - Subject Name not in Question.ipynb\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LazyConfigValue' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/mount/arbeitsdaten46/projekte/dialog-1/kanjurva/Simple-QA-EMNLP-2018/env/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mount/arbeitsdaten46/projekte/dialog-1/kanjurva/Simple-QA-EMNLP-2018/env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# display HTML, so this check can be removed when support for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# IPython 2.x is no longer needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mconsole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_qtconsole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m             \u001b[0;31m# 'HTML output is disabled in QtConsole'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mount/arbeitsdaten46/projekte/dialog-1/kanjurva/Simple-QA-EMNLP-2018/env/lib/python3.6/site-packages/pandas/io/formats/console.py\u001b[0m in \u001b[0;36min_qtconsole\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KernelApp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parent_appname'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             ip.config.get('IPKernelApp', {}).get('parent_appname', \"\"))\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'qtconsole'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfront_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LazyConfigValue' object has no attribute 'lower'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       subject                                         relation   object  \\\n",
       "17188   02_286  location/place_with_neighborhoods/neighborhoods   075s73   \n",
       "4793    01bg1k              baseball/baseball_player/position_s   017drs   \n",
       "21187   06tw28                               music/artist/track   0vp3fq   \n",
       "18730  0slws_1                    music/release_track/recording   0wzyx1   \n",
       "10014    01m1y                media_common/netflix_genre/titles  0crryw4   \n",
       "\n",
       "                                                question  \\\n",
       "17188                     which town is in new york city   \n",
       "4793   does pee wee reese play shortstop or power for...   \n",
       "21187                What is a track by lutricia mcneal?   \n",
       "18730                 Name a recording by nelson mandela   \n",
       "10014     Name a film in the netflix genre celtic music.   \n",
       "\n",
       "                                 predicted_subject_names  \\\n",
       "17188  [{'name': 'new york city', 'score': tensor(64....   \n",
       "4793   [{'name': 'pee wee reese', 'score': tensor(91....   \n",
       "21187  [{'name': 'lutricia mcneal', 'score': tensor(7...   \n",
       "18730  [{'name': 'nelson mandela', 'score': tensor(57...   \n",
       "10014  [{'name': 'celtic music', 'score': tensor(106....   \n",
       "\n",
       "                               predicted_question_tokens  \n",
       "17188             [which, town, is, in, new, york, city]  \n",
       "4793   [does, pee, wee, reese, play, shortstop, or, p...  \n",
       "21187      [what, is, a, track, by, lutricia, mcneal, ?]  \n",
       "18730          [name, a, recording, by, nelson, mandela]  \n",
       "10014  [name, a, film, in, the, netflix, genre, celti...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import nan\n",
    "\n",
    "\n",
    "PREPROCESS = importlib.import_module(\n",
    "                \"notebooks.Simple QA Models.Subject Recognition Data\").preprocess\n",
    "TOKENIZE = importlib.import_module(\n",
    "                \"notebooks.Simple QA Models.Subject Recognition Data\").spacy_tokenize\n",
    "\n",
    "def add_predicted_subject_name(row):\n",
    "    question_tokens = TOKENIZE(PREPROCESS(row['question']))\n",
    "    predicted_subject_names = predict_subject_name(question_tokens)\n",
    "    row['predicted_subject_names'] = predicted_subject_names\n",
    "    row['predicted_question_tokens'] = question_tokens\n",
    "    return row\n",
    "\n",
    "df_dev = df_dev.progress_apply(add_predicted_subject_name, axis=1)\n",
    "df_dev[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Setup\n",
    "\n",
    "Add the True `subject_name` and `start_index` / `end_index` to check the accuracy of our predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ../../notebooks/Simple QA Numbers/HYPOTHESIS - Question Refers to Multiple Subjects.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119bd242ea3544059591d30a52be021b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from functools import partial\n",
    "\n",
    "edit_distance_link_alias = importlib.import_module(\n",
    "                \"notebooks.Simple QA Numbers.HYPOTHESIS - Question Refers to Multiple Subjects\").edit_distance_link_alias\n",
    "normalize = importlib.import_module(\n",
    "                \"notebooks.Simple QA Numbers.HYPOTHESIS - Subject Name not in Question\").normalize\n",
    "\n",
    "# Create a column with the subject_name linked per example\n",
    "df_dev['subject_name'] = df_dev.progress_apply(partial(edit_distance_link_alias, cursor, normalize), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1cbf1dea364252a4cb52c2a09c89eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LazyConfigValue' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/mount/arbeitsdaten46/projekte/dialog-1/kanjurva/Simple-QA-EMNLP-2018/env/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mount/arbeitsdaten46/projekte/dialog-1/kanjurva/Simple-QA-EMNLP-2018/env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# display HTML, so this check can be removed when support for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# IPython 2.x is no longer needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mconsole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_qtconsole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m             \u001b[0;31m# 'HTML output is disabled in QtConsole'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mount/arbeitsdaten46/projekte/dialog-1/kanjurva/Simple-QA-EMNLP-2018/env/lib/python3.6/site-packages/pandas/io/formats/console.py\u001b[0m in \u001b[0;36min_qtconsole\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KernelApp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parent_appname'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             ip.config.get('IPKernelApp', {}).get('parent_appname', \"\"))\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'qtconsole'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfront_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LazyConfigValue' object has no attribute 'lower'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       end_index   object                          predicted_question_tokens  \\\n",
       "17188        7.0   075s73             [which, town, is, in, new, york, city]   \n",
       "4793         4.0   017drs  [does, pee, wee, reese, play, shortstop, or, p...   \n",
       "21187        7.0   0vp3fq      [what, is, a, track, by, lutricia, mcneal, ?]   \n",
       "18730        6.0   0wzyx1          [name, a, recording, by, nelson, mandela]   \n",
       "10014        9.0  0crryw4  [name, a, film, in, the, netflix, genre, celti...   \n",
       "\n",
       "                                 predicted_subject_names  \\\n",
       "17188  [{'name': 'new york city', 'score': tensor(64....   \n",
       "4793   [{'name': 'pee wee reese', 'score': tensor(91....   \n",
       "21187  [{'name': 'lutricia mcneal', 'score': tensor(7...   \n",
       "18730  [{'name': 'nelson mandela', 'score': tensor(57...   \n",
       "10014  [{'name': 'celtic music', 'score': tensor(106....   \n",
       "\n",
       "                                                question  \\\n",
       "17188                     which town is in new york city   \n",
       "4793   does pee wee reese play shortstop or power for...   \n",
       "21187                What is a track by lutricia mcneal?   \n",
       "18730                 Name a recording by nelson mandela   \n",
       "10014     Name a film in the netflix genre celtic music.   \n",
       "\n",
       "                                         question_tokens  \\\n",
       "17188             [which, town, is, in, new, york, city]   \n",
       "4793   [does, pee, wee, reese, play, shortstop, or, p...   \n",
       "21187      [what, is, a, track, by, lutricia, mcneal, ?]   \n",
       "18730          [name, a, recording, by, nelson, mandela]   \n",
       "10014  [name, a, film, in, the, netflix, genre, celti...   \n",
       "\n",
       "                                              relation  start_index  subject  \\\n",
       "17188  location/place_with_neighborhoods/neighborhoods          4.0   02_286   \n",
       "4793               baseball/baseball_player/position_s          1.0   01bg1k   \n",
       "21187                               music/artist/track          5.0   06tw28   \n",
       "18730                    music/release_track/recording          4.0  0slws_1   \n",
       "10014                media_common/netflix_genre/titles          7.0    01m1y   \n",
       "\n",
       "           subject_name subject_name_tokens  \n",
       "17188     new york city   (new, york, city)  \n",
       "4793      pee wee reese   (pee, wee, reese)  \n",
       "21187  lutricia  mcneal  (lutricia, mcneal)  \n",
       "18730    nelson mandela   (nelson, mandela)  \n",
       "10014      celtic music     (celtic, music)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "# Adds:\n",
    "# - question_tokens\n",
    "# - subject_name\n",
    "# - start_index\n",
    "# - end_index\n",
    "find_subject_name_span = importlib.import_module(\n",
    "                \"notebooks.Simple QA Models.Subject Recognition Data\").find_subject_name_span\n",
    "\n",
    "# Create a column with the subject_name linked per example\n",
    "df_dev = df_dev.progress_apply(find_subject_name_span, axis=1)\n",
    "df_dev[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_pickle('step_1_predict_subject_name.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dev = pd.read_pickle('step_1_predict_subject_name.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis - Correct Span\n",
    "\n",
    "We determine the correct subject name span and compare it to the predicted subject name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c468254d40ee4aca879da47b4e36ac57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Top 1: 0.954999 [20309 of 21266]\n",
      "Accuracy Top 2: 0.973432 [20701 of 21266]\n",
      "Accuracy Top 3: 0.980626 [20854 of 21266]\n",
      "Accuracy Top 4: 0.984811 [20943 of 21266]\n",
      "Accuracy Top 5: 0.987539 [21001 of 21266]\n",
      "Accuracy Top 6: 0.989091 [21034 of 21266]\n",
      "Accuracy Top 7: 0.991019 [21075 of 21266]\n",
      "Accuracy Top 8: 0.991959 [21095 of 21266]\n",
      "Accuracy Top 9: 0.992899 [21115 of 21266]\n",
      "Accuracy Top 10: 0.993746 [21133 of 21266]\n",
      "Accuracy Top 11: 0.994498 [21149 of 21266]\n",
      "Accuracy Top 12: 0.994921 [21158 of 21266]\n",
      "Accuracy Top 13: 0.995251 [21165 of 21266]\n",
      "Accuracy Top 14: 0.995627 [21173 of 21266]\n",
      "Accuracy Top 15: 0.995815 [21177 of 21266]\n",
      "Accuracy Top 16: 0.996144 [21184 of 21266]\n",
      "Accuracy Top 17: 0.996238 [21186 of 21266]\n",
      "Accuracy Top 18: 0.996755 [21197 of 21266]\n",
      "Accuracy Top 19: 0.997414 [21211 of 21266]\n",
      "Accuracy Top 20: 0.997555 [21214 of 21266]\n",
      "Accuracy Top 21: 0.997884 [21221 of 21266]\n",
      "Accuracy Top 22: 0.997978 [21223 of 21266]\n",
      "Accuracy Top 23: 0.998072 [21225 of 21266]\n",
      "Accuracy Top 24: 0.998119 [21226 of 21266]\n",
      "Accuracy Top 25: 0.998354 [21231 of 21266]\n",
      "Accuracy Top 26: 0.998401 [21232 of 21266]\n",
      "Accuracy Top 27: 0.998683 [21238 of 21266]\n",
      "Accuracy Top 28: 0.998730 [21239 of 21266]\n",
      "Accuracy Top 29: 0.998824 [21241 of 21266]\n",
      "Accuracy Top 30: 0.998918 [21243 of 21266]\n",
      "Accuracy Top 31: 0.998918 [21243 of 21266]\n",
      "Accuracy Top 32: 0.998918 [21243 of 21266]\n",
      "Accuracy Top 33: 0.998918 [21243 of 21266]\n",
      "Accuracy Top 34: 0.998965 [21244 of 21266]\n",
      "Accuracy Top 35: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 36: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 37: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 38: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 39: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 40: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 41: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 42: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 43: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 44: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 45: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 46: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 47: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 48: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 49: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 50: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 51: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 52: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 53: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 54: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 55: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 56: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 57: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 58: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 59: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 60: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 61: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 62: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 63: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 64: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 65: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 66: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 67: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 68: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 69: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 70: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 71: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 72: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 73: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 74: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 75: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 76: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 77: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 78: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 79: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 80: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 81: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 82: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 83: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 84: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 85: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 86: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 87: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 88: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 89: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 90: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 91: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 92: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 93: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 94: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 95: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 96: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 97: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 98: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 99: 0.999013 [21245 of 21266]\n",
      "Accuracy Top 100: 0.999013 [21245 of 21266]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "accuracies = [0] * 100\n",
    "total = 0\n",
    "\n",
    "def is_correct(row, top_k):\n",
    "    for i in range(min(top_k, len(row['predicted_subject_names']))):\n",
    "        if (row['start_index'] == row['predicted_subject_names'][i]['start_index'] and\n",
    "            row['end_index'] == row['predicted_subject_names'][i]['end_index']):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "for index, row in tqdm_notebook(df_dev.iterrows(), total=df_dev.shape[0]):\n",
    "    if not isinstance(row['subject_name'], str):\n",
    "        continue\n",
    "        \n",
    "    total += 1\n",
    "    accuracies = [count + is_correct(row, i + 1) for i, count in enumerate(accuracies)]\n",
    "\n",
    "for i, count in enumerate(accuracies):\n",
    "    print('Accuracy Top %d: %f [%d of %d]' % (i + 1, count / total, count, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis - Normalized Link\n",
    "\n",
    "We normalize the correct subject name and compare it to the predicted name normalized.\n",
    "\n",
    "We expect this to be lower than the span analysis because in \"HYPOTHESIS - Subject Name not in Question\", we found that 97.85% of the time the subject name normalized is not in the question; therefore, some spans that are correct will not be equal to the subject name normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "normalize = importlib.import_module(\n",
    "                \"notebooks.Simple QA Numbers.HYPOTHESIS - Subject Name not in Question\").normalize\n",
    "tokenize = importlib.import_module(\n",
    "                \"notebooks.Simple QA Models.Subject Recognition Data\").spacy_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4e9685f61f4a039b9c4245496bb34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Top 1: 0.943102 [20056 of 21266]\n",
      "Accuracy Top 2: 0.959795 [20411 of 21266]\n",
      "Accuracy Top 3: 0.966754 [20559 of 21266]\n",
      "Accuracy Top 4: 0.970940 [20648 of 21266]\n",
      "Accuracy Top 5: 0.973479 [20702 of 21266]\n",
      "Accuracy Top 6: 0.975031 [20735 of 21266]\n",
      "Accuracy Top 7: 0.976582 [20768 of 21266]\n",
      "Accuracy Top 8: 0.977570 [20789 of 21266]\n",
      "Accuracy Top 9: 0.978604 [20811 of 21266]\n",
      "Accuracy Top 10: 0.979357 [20827 of 21266]\n",
      "Negative Sample:\n",
      "\n",
      "| Index | Predicted Subject Name | Subject Name |\n",
      "| --- | --- | --- |\n",
      "| 0 | ['enforcement', 'enforcement agency', 'law enforcement', 'law enforcement agency', 'agency'] | law enforcement agency |\n",
      "| 1 | ['outlying islands', 'states minor outlying islands', 'islands', 'united states minor outlying islands', 'minor outlying islands'] | united states minor outlying islands |\n",
      "| 2 | ['the greatest hits', 'the greatest hits album', 'greatest hits', 'greatest hits album', 'the greatest'] | greatest hits |\n",
      "| 3 | ['heroines mantle', 'heroines', 'mantle', 'heroines mantle ?', 'is heroines mantle'] | heroine's mantle |\n",
      "| 4 | ['album', 'cover album', 'cover', 'album by', 'cover album by'] | ken hirai |\n",
      "| 5 | ['green whiskers', 'the green whiskers', 'soldier with the green whiskers', 'with the green whiskers', 'whiskers'] | soldier with the green whiskers |\n",
      "| 6 | ['marco ( animorphs )', 'marco ( animorphs', 'marco (', 'marco', 'marco ( animorphs ) appear'] | marco |\n",
      "| 7 | ['st helens rlfc', 'st helens', 'helens rlfc', 'the st helens rlfc', 'st'] | st helens rfc |\n",
      "| 8 | ['river dee , aberdeenshire', 'dee , aberdeenshire', 'river dee ,', 'river dee , aberdeenshire in', 'is river dee , aberdeenshire'] | river dee |\n",
      "| 9 | ['mandy bright', \"mandy bright 's\", 'mandy', 'bright', 'is mandy bright'] | mandy |\n",
      "| 10 | ['felix enriquez alcala', 'enriquez alcala', 'felix enriquez', 'by felix enriquez alcala', 'alcala'] | thriller |\n",
      "| 11 | ['sweet lovers : myself;yourself best song album', 'sweet lovers : myself;yourself best song', 'sweet lovers : myself;yourself best song album ?', 'lovers : myself;yourself best song album', 'is sweet lovers : myself;yourself best song album'] | sweet lover's: myselfyourself best song album |\n",
      "| 12 | ['the fifth season of deja vu', 'the fifth season of deja vu (', 'the fifth season of deja vu ( the', 'fifth season of deja vu', 'the fifth season of deja vu ( the outer'] | deja vu |\n",
      "| 13 | ['drama film', 'drama', 'film', 'the drama film', 'drama film where'] | black-and-white |\n",
      "| 14 | ['eleanor roosevelt national historic', 'eleanor roosevelt national historic site', 'eleanor roosevelt national', 'roosevelt national historic', 'the eleanor roosevelt national historic'] | eleanor roosevelt national historic site |\n",
      "| 15 | ['aninuddha roy chowdhury', \"aninuddha roy chowdhury 's\", 'roy chowdhury', 'is aninuddha roy chowdhury', 'aninuddha roy'] | aniruddha roy chowdhury |\n",
      "| 16 | ['the daily kos', 'daily kos', 'kos', 'the daily', 'daily'] | daily kos |\n",
      "| 17 | ['accident', 'an accident', 'an', 'airlines', 'in an accident'] | scandinavian airlines |\n",
      "| 18 | ['the habit', 'the habit in', 'habit', 'the', 'is the habit'] | habit |\n",
      "| 19 | ['adventure', 'an adventure', 'adventure cvg', 'is an adventure', 'an adventure cvg'] | adeventure |\n",
      "| 20 | ['2010 fantasia festival', '2010 fantasia', 'fantasia festival', 'the 2010 fantasia festival', '2010'] | 2010 fantasia film festival |\n",
      "| 21 | ['alpha tau omega chapter', 'alpha tau omega', 'tau omega chapter', 'a alpha tau omega chapter', 'alpha tau'] | alpha tau omega |\n",
      "| 22 | ['american', 'parody', '2007 american', '2007', 'american film parody'] | parody |\n",
      "| 23 | ['science and technology public university', 'and technology public university', 'technology public university', 'public university', 'university'] | public university |\n",
      "| 24 | ['jane', 'jane child', 'is jane', 'jane child pop', 'is jane child'] | jane child |\n",
      "| 25 | ['cambria county', 'cambria county ,', 'cambria county , pennsylvania', 'cambria', 'county'] | cambria county, pennsylvania |\n",
      "| 26 | ['opens and runs restaurants', 'opens and runs', 'opens and runs restaurants professionally', 'and runs restaurants', 'who opens and runs restaurants'] | entrepreneur |\n",
      "| 27 | ['blazej balaz express', 'blazej balaz', 'balaz express', 'blazej balaz express themselves', 'did blazej balaz express'] | blaej bal |\n",
      "| 28 | ['kish island', 'kish island part', 'kish', 'island', 'is kish island'] | kish |\n",
      "| 29 | ['boradcasts olivia newton - john', 'olivia newton - john', 'who boradcasts olivia newton - john', 'boradcasts olivia newton -', 'newton - john'] | olivia newton-john |\n",
      "| 30 | ['madame', 'for madame', 'music for madame', 'madame from', 'for madame from'] | music for madame |\n",
      "| 31 | ['hydrogen peroxide formula', 'peroxide formula', 'hydrogen peroxide', 'formula', 'peroxide'] | liquid |\n",
      "| 32 | ['virginia highlands community college campus', 'virginia highlands community college', 'highlands community college campus', 'highlands community college', 'virginia highlands community'] | virginia highlands community college |\n",
      "| 33 | ['historical novels', 'historical', 'novels', 'of historical novels', 'of historical'] | historical novel |\n",
      "| 34 | ['whiskey , mystics & men', ', mystics & men', 'wrote whiskey , mystics & men', 'whiskey , mystics &', 'mystics & men'] | whiskey, mystics and men |\n",
      "| 35 | ['john binder', 'john binder identifies', 'binder', 'john', 'john binder identifies with'] | john binden |\n",
      "| 36 | ['the daughter of irene', 'daughter of irene', 'the daughter of irene born', 'was the daughter of irene', 'the daughter of'] | irene born |\n",
      "| 37 | ['michael nolands', 'michael nolands profession', 'nolands', 'is michael nolands', 'michael'] | michael noland |\n",
      "| 38 | ['the bee gees', 'the bee', 'bee gees', 'the bee gees released', 'the'] | album |\n",
      "| 39 | ['planet song', 'planet', 'song', 'planet song ?', 'the planet song'] | planet |\n",
      "| 40 | ['r.j.s latest arrival', 'latest arrival', 'r.j.s latest arrival is', 'r.j.s latest', 'arrival'] | r.j.'s latest arrival |\n",
      "| 41 | ['bengali', 'bengali people', 'the bengali', 'the bengali people', 'people'] | bengalis |\n",
      "| 42 | ['midfielder', 'defensive midfielder', 'midfielder born', 'state', 'of'] | state of palestine |\n",
      "| 43 | ['francis xavier : the samurais lost treasure', 'xavier : the samurais lost treasure', 'film francis xavier : the samurais lost treasure', 'francis xavier : the samurais lost', ': the samurais lost treasure'] | francis xavier: the samurai's lost treasure |\n",
      "| 44 | ['female', 'female fictional', 'a female', 'female fictional character', 'a female fictional'] | flight |\n",
      "| 45 | ['ill remember', 'ill', 'remember', 'is ill remember', 'is ill'] | i'll remember |\n",
      "| 46 | ['jeff beaucars', 'beaucars', 'jeff beaucars profession', 'is jeff beaucars', 'jeff'] | jeff beaucar |\n",
      "| 47 | ['the brothers in arms : double time', 'brothers in arms : double time', 'the brothers in arms : double time was', 'in arms : double time', 'the brothers in arms : double'] | brothers in arms: double time |\n",
      "| 48 | ['live album', 'album', 'live', 'live album by', 'album by'] | chicago |\n",
      "| 49 | ['its in your eyes', 'in your eyes', 'its in your', 'composition its in your eyes', 'your eyes'] | its in your eyes |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from lib.utils import format_pipe_table\n",
    "\n",
    "negative_sample = []\n",
    "accuracies = [0] * 10\n",
    "total = 0\n",
    "\n",
    "def is_correct(row, top_k):\n",
    "    subject_name = normalize(' '.join(tokenize(row['subject_name'])))\n",
    "    for i in range(min(top_k, len(row['predicted_subject_names']))):\n",
    "        predicted_subject_name = normalize(row['predicted_subject_names'][i]['name'])\n",
    "        if predicted_subject_name == subject_name:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "for index, row in tqdm_notebook(df_dev.iterrows(), total=df_dev.shape[0]):\n",
    "    if not isinstance(row['subject_name'], str):\n",
    "        continue\n",
    "        \n",
    "    total += 1\n",
    "    accuracies = [count + is_correct(row, i + 1) for i, count in enumerate(accuracies)]\n",
    "    if not is_correct(row, 1):\n",
    "        negative_sample.append({\n",
    "            'Subject Name': row['subject_name'],\n",
    "            'Predicted Subject Name': [row['predicted_subject_names'][i]['name']\n",
    "                                       for i in range(min(5, len(row['predicted_subject_names'])))],\n",
    "        })\n",
    "\n",
    "for i, count in enumerate(accuracies):\n",
    "    print('Accuracy Top %d: %f [%d of %d]' % (i + 1, count / total, count, total))\n",
    "print('Negative Sample:\\n')\n",
    "print(format_pipe_table(negative_sample[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
